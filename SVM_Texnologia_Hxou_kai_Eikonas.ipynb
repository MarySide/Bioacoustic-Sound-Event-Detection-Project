{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_Texnologia_Hxou_kai_Eikonas.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLvpxC09Z11-",
        "outputId": "9592b8a4-9ee0-4582-ed81-b75d2426b1db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOa5G1b1OVzE"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load data from csv file\n",
        "X =  pd.read_csv('/content/gdrive/MyDrive/FEATURES.csv')\n",
        "\n",
        "X = X.to_numpy()\n",
        "Y = X[:,21]\n",
        "X = X[:, :21]\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=28)\n",
        "\n",
        "scale_gamma = 1/(21 * X.var())\n",
        "print('gamma if set to scale is:')\n",
        "print(scale_gamma)\n",
        "\n",
        "# SVM\n",
        "print('fitting...')\n",
        "clf = SVC(C=10.0, gamma=0.00001, kernel='rbf') \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#print(SVC.get_params)\n",
        "acc = clf.score(X_test, y_test)\n",
        "print(acc)\n",
        "print(\"acc = %0.4f\" % acc)\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "# Generate confusion matrix\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "import matplotlib.pyplot as plt\n",
        "matrix = plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues, normalize='true')\n",
        "plt.title('Confusion matrix for the animal classifier')\n",
        "plt.show(matrix)\n",
        "plt.show()\n",
        "\n",
        "#######################################################################\n",
        "# Grid search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        " \n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 20, 30, 40, 50, 60, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
        "              'kernel': ['rbf']}\n",
        " \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        " \n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        " \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)\n",
        "\n",
        "grid_predictions = grid.predict(X_test)\n",
        " \n",
        "# print classification report\n",
        "print(classification_report(y_test, grid_predictions))\n",
        "\n"
      ]
    }
  ]
}